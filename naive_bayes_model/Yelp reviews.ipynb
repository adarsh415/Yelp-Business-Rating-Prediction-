{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read Yelp csv file\n",
    "path='D:/Adarsh_Laptop/studetmater/python/pycon-2016-tutorial/data/yelp.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[(data.stars == 5) | (data.stars == 1)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Retreive only text and stars columns\n",
    "X_data = data['text']\n",
    "y_data = data['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing data and found none\n",
    "X_data.isnull().sum()\n",
    "y_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086L,)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086L,)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064L,)\n",
      "(1022L,)\n",
      "(3064L,)\n",
      "(1022L,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X_data,y_data,random_state=1)\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer shall be used to work on text data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Vectorize Test data\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "y_train=lb.fit_transform(y_train)\n",
    "y_test=lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Applying Naive Bayes classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MultinomialNB for prediction\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameter  selection and tunning\n",
    "vect_cv = CountVectorizer()\n",
    "cv_X_data = vect_cv.fit_transform(X_data)\n",
    "cv_y_data = lb.fit_transform(y_data)\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "alpha = np.arange(0,1,0.1)\n",
    "acc_score=[]\n",
    "for alpha in alpha:\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "    cv_accuracy = cross_val_score(nb,cv_X_data,cv_y_data,cv=10,scoring = 'accuracy').mean()\n",
    "    acc_score.append(cv_accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926105581903\n"
     ]
    }
   ],
   "source": [
    "print max(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.41409272719498513),\n",
       " (0.10000000000000001, 0.92194130050451084),\n",
       " (0.20000000000000001, 0.92120660270379806),\n",
       " (0.30000000000000004, 0.92316859437526788),\n",
       " (0.40000000000000002, 0.92439108826279826),\n",
       " (0.5, 0.92610558190343895),\n",
       " (0.60000000000000009, 0.92414478581061366),\n",
       " (0.70000000000000007, 0.92487648435800318),\n",
       " (0.80000000000000004, 0.92438328313669893),\n",
       " (0.90000000000000002, 0.92584907727831656)]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " zip(np.arange(0,1,0.1),acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from cross_val_score , alpha=0.5 will give the best accuracy \n",
    "nb = MultinomialNB(alpha=0.5)\n",
    "nb.fit(X_train_dtm,y_train)\n",
    "nb_predict = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954707985697\n"
     ]
    }
   ],
   "source": [
    "f1_Score_NB=metrics.f1_score(y_test,nb_predict)\n",
    "print f1_Score_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf_matrix= metrics.confusion_matrix(y_test,nb_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>39</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>801</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>182</td>\n",
       "      <td>840</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   All\n",
       "True                     \n",
       "0          145   39   184\n",
       "1           37  801   838\n",
       "All        182  840  1022"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, nb_predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.inverse_transform(y_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TN=conf_matrix[0,0]\n",
    "FP=conf_matrix[0,1]\n",
    "FN=conf_matrix[1,0]\n",
    "TP=conf_matrix[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92563600782778865"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification Accuracy\n",
    "Classification_Accuracy_NB=metrics.accuracy_score(y_test,nb_predict)\n",
    "Classification_Accuracy_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.074363992172211346"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification Error\n",
    "Classification_Error_NB=1 - metrics.accuracy_score(y_test,nb_predict)\n",
    "Classification_Error_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95584725536992843"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sensitivity : is the classifier to detecting positive instances , also True Positive Rate\" or \"Recall\"\n",
    "recall_NB= metrics.recall_score(y_test,nb_predict)\n",
    "recall_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76086956521739135"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specificity: When the actual value is negative, how often is the prediction correct? \n",
    "#How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "\n",
    "Specificity_NB=(TN / float(TN + FP))\n",
    "Specificity_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate predicted probability \n",
    "##I want probability of getting rating 5 so \n",
    "nb_predict_prob=nb.predict_proba(X_test_dtm)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211956521739\n"
     ]
    }
   ],
   "source": [
    "#False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
    "print(FP/ float(FP+TN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948235294118\n"
     ]
    }
   ],
   "source": [
    "#Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "#How \"precise\" is the classifier when predicting positive instances?\n",
    "print (TP/float(TP+FP))\n",
    "Precision_NB= metrics.precision_score(y_test,nb_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "#print rating 1 reviews which are falsely callisified as positive i.e rating 5 ,diplay False Postive review comments\n",
    "print len(X_test[(nb_predict == 1) & (y_test == 0)])\n",
    "\n",
    "#X_test[nb_predict > y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you like the stuck up Scottsdale vibe this is a good place for you. The food isn't impressive. Nice outdoor seating.\""
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False postive review\n",
    "X_test[1781]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "#print rating 5 reviews which are falsely callisified as negative i.e rating 1,diplay True Negative review comments\n",
    "print len(X_test[(nb_predict == 0) & (y_test == 1)])\n",
    "#X_test[ nb_predict < y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I really enjoyed my mani/pedi with Trisha!  She took her time and taught me about manicuring my nails from home which I loved.\\n\\nI went in for the Groupon basic mani/pedi deal and left feeling like I got a lot more! It was the most pleasant experience I've had at a nail salon. The conversation was easy and Trish is a great person. I will be coming back to Trish for nails again! \\n\\nThe entire staff was friendly and professional. Great Salon!!\""
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Negative , review which is falsely callasified as Rating 1\n",
    "X_test[1438]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.99693641,  1.        ,  0.99624713,  1.        ])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 5 probabilty of getting 5 rating\n",
    "nb_predict_prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94623261907232536"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_auc= metrics.roc_auc_score(y_test,nb_predict_prob)\n",
    "nb_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB_Prop</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.954708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classification_Accuracy</td>\n",
       "      <td>0.925636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classification_Error</td>\n",
       "      <td>0.074364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.955847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.953571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.946233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   NB_Prop     Value\n",
       "0                 f1_score  0.954708\n",
       "1  Classification_Accuracy  0.925636\n",
       "2     Classification_Error  0.074364\n",
       "3                   Recall  0.955847\n",
       "4              Specificity  0.760870\n",
       "5                Precision  0.953571\n",
       "6                      AUC  0.946233"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val= [f1_Score_NB,Classification_Accuracy_NB,Classification_Error_NB,recall_NB,Specificity_NB,Precision_NB,nb_auc]\n",
    "name=['f1_score','Classification_Accuracy','Classification_Error','Recall','Specificity','Precision','AUC']\n",
    "\n",
    "NB_DataFrame = pd.DataFrame(zip(name,val),columns=['NB_Prop','Value'])\n",
    "NB_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Solving this problem through Logistice regression\n",
    "# We will try out all classifier and compare them all how fare to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parameter selection and tunning\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "alpha = np.arange(1,5,0.1)\n",
    "acc_score=[]\n",
    "for alpha in alpha:\n",
    "    lr = LogisticRegression(C=alpha)\n",
    "    cv_accuracy = cross_val_score(lr,cv_X_data,cv_y_data,cv=10,scoring = 'accuracy').mean()\n",
    "    acc_score.append(cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938823116849\n"
     ]
    }
   ],
   "source": [
    "print max(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zip(np.arange(1,5,0.1),acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1.1)\n",
    "lr.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95497630331753547"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test,lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>44</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>806</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>172</td>\n",
       "      <td>850</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   All\n",
       "True                     \n",
       "0          140   44   184\n",
       "1           32  806   838\n",
       "All        172  850  1022"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "lr_conf_matrix = metrics.confusion_matrix(y_test,lr_pred) \n",
    "#print the confusion matrix for better understanding with row and columns\n",
    "pd.crosstab(y_test,lr_pred,rownames=['True'],colnames=['Predicted'],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925636007828\n"
     ]
    }
   ],
   "source": [
    "#Classification Accuracy\n",
    "print metrics.accuracy_score(y_test,lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0743639921722\n"
     ]
    }
   ],
   "source": [
    "#Classification Error\n",
    "print 1 - metrics.accuracy_score(y_test,lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961813842482\n"
     ]
    }
   ],
   "source": [
    "#Sensitivity : is the classifier to detecting positive instances , also True Positive Rate\" or \"Recall\"\n",
    "print metrics.recall_score(y_test,lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TN=lr_conf_matrix[0,0]\n",
    "FP=lr_conf_matrix[0,1]\n",
    "FN=lr_conf_matrix[1,0]\n",
    "TP=lr_conf_matrix[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76086956521739135"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specificity: When the actual value is negative, how often is the prediction correct? \n",
    "#How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "\n",
    "Specificity_lr=(TN / float(TN + FP))\n",
    "Specificity_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.239130434783\n"
     ]
    }
   ],
   "source": [
    "#False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
    "print(FP/ float(FP+TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948235294118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94823529411764707"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "#How \"precise\" is the classifier when predicting positive instances?\n",
    "print (TP/float(TP+FP))\n",
    "precision_lr=metrics.precision_score(y_test, lr_pred)\n",
    "precision_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate predicted probability \n",
    "##I want probability of getting rating 5 so \n",
    "lr_predict_prob=lr.predict_proba(X_test_dtm)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False positive , review which are falsely predicted as rating 5\n",
    "X_test[lr_pred > y_test].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#True Negative , review which are falsely predicted as rating 1\n",
    "X_test[lr_pred < y_test].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813953488372\n"
     ]
    }
   ],
   "source": [
    "#False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96883755318045039"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate AUC for Logistice regression ,\n",
    "auc_logistic = metrics.roc_auc_score(y_test,lr_predict_prob)\n",
    "auc_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let List out all the accuracy and validating facts from both the algorithms\n",
    "#First we will go with Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM classifier with kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_predict=svc.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81996086105675148"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "svc_acuracy=metrics.accuracy_score(y_test,svc_predict)\n",
    "svc_acuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
